---
title: "Working Pollock ML model with Decadal Aggregation"
author: "Max Kuempel, Tzu-Chun Kao, Owen Peterson"
date: "2025-06-2"
output:
  pdf_document: default
---

Packages used are biooracler, terra, randomForest, and caret. biooracler and terra allow for direct downloading of bio-ORACLE layers in R and raster plotting and analysis respectively. randomForest and caret allow for easy random forest modeling in R. caret is a package that allows easy tuning and cross validation for randomforest models. The devtools package is used to install bioracler from its github page. gridExtra, tidyTerra and viridis are used for figure creation.

NOTE: Rtools may be required for biooracler. Download from here: <https://cran.r-project.org/bin/windows/Rtools/>

Use the PackageInstall.R script to install all necessary packages.

# PREDICTION PARAMETER SPECIFICATION

```{r}
###SPECIFY ALL PARAMETERS HERE< AND THEN RUN ALL
year_to_predict <- 2040 #Year to compare to a 2010 baseline
pathway <- "ssp370"# climate pathway to use, options are
#"ssp119"
#"ssp126"
#"ssp245"
#"ssp370"
#"ssp460"
#"ssp585"


```

Specify Layers to use

**Loading Bio- layers with bioracler**

Bio-ORACLE provides 0.05 degree near global rasters (seam near the anti-meridan). There is a raster for each decade. For training the model, baseline rasters are used.

All layers for a particular property can be explored with the list_layers("property") function. The specific variables for a layer (mean, min, max etc) can be explored with info_layer("layer name").

In order to download layers from bioracler, a set of constraints is defined. Lat and Long values are taken from the extent of the NOAA Survey Trawls as to not download extra data. date is set to January 1st 2000 in order to download the 2000 baseline layer, and January 1st 2010 for 2010-2020.

To ensure each decade downloads the same variables, all variables are defined in one place. Variables are named with a prefix describing the layer, and a suffix: possible suffixes are

-   mean: Average for the decade

-   max: Maximum for the decade

-   min: Minimum for the decade

-   range: Range of values (difference of max and min for a decade).

-   ltmax: Average Highest value for a year in the decade

-   ltmin: Average lowest value for a year in the decade

```{r Specifying Layers and Variables}
#layer list. use biooracler ID's and baseline time frame
LayerList <- list(
  SeaIce = "sithick_baseline_2000_2020_depthsurf",
  o2 = "o2_baseline_2000_2018_depthmax",
    BenthicTemp = "thetao_baseline_2000_2019_depthmax",
    SeaVel = "sws_baseline_2000_2019_depthmax",
 Chlor = "chl_baseline_2000_2018_depthsurf"
)


#all variables start with "sithick_" for sea ice
SeaIceThicknessVar <- c("sithick_max")
#all variables start with" o2_" for dissolved oxygen
o2Var <- c("o2_range")
#all varialbes start with "thetao_ " for temperature
BenthicTempVar <- c("thetao_range","thetao_max","thetao_min")
#all variables start with "sws" for current
SeaVelVar <- c("sws_max")
#all variables start with "chl_" for chlorophyll
ChlorVar <- c("chl_ltmax","chl_ltmin")

####################################
#if adding a new layer, match biooracler ID(left) to variable list (right)
#####################################

#Var List
VarList <- list(
  SeaIceID = SeaIceThicknessVar,
  o2ID = o2Var,
  BenthicTempID = BenthicTempVar,
  SeaVelID = SeaVelVar,
  ChlorID = ChlorVar
)

```

Beyond this point, code should run automatically based on parameters above.

Load all required packages

```{r Package Library, message=FALSE, warning=FALSE}
#Libraries for general use.  
library(biooracler)
library(terra)

#Used for Random Forest Model.
library(randomForest)
library(caret)

#Used for final plots
library(gridExtra) #Side by side plotting
library(tidyterra) #ggplot and terra integration
library(viridis)
```

**Reading and processing the pollock trawl surveys**

The trawl surveys come in a .csv file named "survey-points-data.csv." It contains the HaulID, Stratum, lat and long of the trawl, depth of trawl, year of trawl and weight catch per unit effort (kg/ha). HaulID allows matching of this data with a greater metadata file containing the exact start and end coordinates of the trawl path, net properties and more.

First it is read into the R environment with the read.csv function. Data for 2000-2010 and 2010-2020 are loaded in separately (as to match corresponding decadal Bio-ORACLE layers.)

Weight catch per unit effort (kg of fish per hectare trawled, shortened to wtcpue) values above 0 are selected and log transformed.

```{r Reading the Trawl Surveys}
#reads the trawl survey CSV into R as an object survey.points.data. 
survey.points.data <- read.csv("Survey_Trawls/survey-points-data.csv")
#reads subset of survey.points by year

#2000-2010 survey points
x2000Survey <- subset(survey.points.data, (Year >= 2000 & Year <= 2010))
x2000Survey <- subset(x2000Survey, (wtcpue > 0))
hist(x2000Survey$wtcpue,main= "Pre log transformed catches (2000-2010)")
x2000Survey$wtcpue <- log(x2000Survey$wtcpue)
hist(x2000Survey$wtcpue,main= "Log transformed catches (2000-2010)")


x2010Survey <- subset(survey.points.data, (Year >= 2010 & Year <= 2020))
x2010Survey <- subset(x2010Survey, (wtcpue > 0))
hist(x2010Survey$wtcpue,main= "Pre log transformed catches (2010-2020)")
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
hist(x2010Survey$wtcpue,main= "Log transformed catches (2010-2020)")

#remove full dataset from R enviroment
remove(survey.points.data)
```

```{r DefiningTrainingConstraints}
#Training constraints bound in all 2000-2020 trawl data
latitude_train = c(52, 64) 
longitude_train = c(-157, -179.975)
```

```{r Download Function}

biooracle_download <- function(layer, variables, year,  lat, long) {
  time = c(paste0(year, '-01-01T00:00:00Z'),
paste0(year, '-01-01T00:00:00Z'))
  constraints = list(time, lat, long)
  names(constraints) = c("time", "latitude", "longitude")
  
  download_layers(layer, variables = variables,  constraints = constraints)
  
}
```

```{r 2000 Layer Download}
year <- 2000
LayerNames2000 <- c()#list of layer names allows easy creation of training data
#uses lat and lon from lattitude_train and longitude_train
for (i in 1:length(LayerList)) {
 layer = biooracle_download(LayerList[[i]], 
                     VarList[[i]], 
                     year, 
                     latitude_train, 
                     longitude_train)
  assign(paste0(names(LayerList[i]),as.character(year)), layer )
  remove(layer) #gets rid of last duplicate layer
  LayerNames2000 <-
    append(LayerNames2000, 
           paste0(names(LayerList[i]),as.character(year)))
  }
```

```{r 2010 Layer Download}
year <- 2010
LayerNames2010 <- c()
#uses lat and lon from lattitude_train and longitude_train
for (i in 1:length(LayerList)) {
 layer = biooracle_download(LayerList[[i]], 
                     VarList[[i]], 
                     year, 
                     latitude_train, 
                     longitude_train)
  assign(paste0(names(LayerList[i]),as.character(year)), layer )
  remove(layer) #gets rid of last duplicate layer
  LayerNames2010 <-
    append(LayerNames2010, 
           paste0(names(LayerList[i]),as.character(year)))
  }
```

Depth is downloaded separately of other layers as its date in Bio-ORACLE is set to 1970. Same geographic constraints are used

```{r Bathymetry Download}
depthvariables = "bathymetry_mean" #mean depth per cell. 

Depth <- biooracle_download("terrain_characteristics",
                   depthvariables, 
                   1970, 
                   latitude_train, 
                   longitude_train)
```

In order to train a model, Ocean conditions must be matched to wtcpue values through matched latitudes and longitudes. The extract function allows for this. By extracting a vector of all data point coordinates we can extract Bio-ORACLE raster values at each coordinate and combine into a data frame for that decade,called MultipleData[start of decade]. For training the model, a version of MultipleData is made with all variable except the latitudes and longitudes, with both decades included. This is so that the model does not take these into account. Survey trawls are made roughly at the same points but are slightly off year to year. To aggregate the trawl data temporarily to the same time scale of the rasters, dplyr is used to group points in multiples data based off of properties and the mean wtcpue is calculated for points in the same cell.

NOTE: this operates off the assumption that two separate cells in bio-ORACLE will not share all properties, due to high decimal precision this is extremely unlikely. Looking for an alternative to this or pairwise distance calculation is an area of active improvement .

The unique() function is then used to remove duplicate points (will interfere with model training).

```{r Extracing and Combining data}
#Creates a new matrix of the lattitudes and longitudes of every trawl
Coord2000 <- cbind(x2000Survey$LON,x2000Survey$LAT)
Coord2010 <- cbind(x2010Survey$LON, x2010Survey$LAT) 

#The "extract" function takes in a lat and long and outputs the value of the raster at that point
#by using it on the whole matrix b, it outputs a list in order of the raster values.
#process is repeated for all bio-ORACLE layers before being bound into a single data frame

RastList2000 <- lapply(LayerNames2000,FUN = get)
MultipleData2000 <- lapply(RastList2000, y = Coord2000, 
                           FUN = terra::extract) %>%
                    as.data.frame()%>% mutate(wtcpue = x2000Survey$wtcpue)
  
RastList2010 <- lapply(LayerNames2010,FUN = get)
MultipleData2010 <- lapply(RastList2010, y = Coord2010, 
                           FUN = terra::extract) %>%
                    as.data.frame()%>% mutate(wtcpue = x2010Survey$wtcpue)
#add in depth
DepthData <- rbind(terra::extract(Depth, Coord2000),
                   terra::extract(Depth, Coord2010))

TrainingData <- rbind(MultipleData2000,MultipleData2010)
TrainingData$depth <- DepthData$bathymetry_mean

#Displays the first few rows of the data. 
head(TrainingData)

#mutate aggregation of training data
library(tidyverse)
TrainingData <- TrainingData %>%
  group_by(thetao_range, sithick_max,o2_range,depth) %>%
  mutate(
    meanwtcpue = mean(wtcpue)
  )%>%
  mutate(wtcpue = NULL)#removes column


#remove duplicate points
TrainingData <- unique(TrainingData)

#clean up memory
remove(MultipleData2000)
remove(MultipleData2010)
rm(list = LayerNames2000)
rm(list = LayerNames2010)
remove(RastList2000)
remove(RastList2010)
remove(Depth)
remove(DepthData)
remove(list = c("x2000Survey", "x2010Survey", "Coord2000","Coord2010"))
```

**Creating the Random Forest Model**

The model is created in the randomForest package. It is trained off of 70% of the data and tested on the other 30% (randomly assigned). For repeat ability, a set seed of 222 is used.

```{r}

set.seed(222)
#Creates a random list of 70% 1 and 30% 2 that is the same length as the training data. 
#Model is trained off all values corresponding to a 1 (70%)
#30% is set aside (assinged a 2)
ind <- sample(2,nrow(TrainingData), replace = TRUE,prob = c(0.7,0.3))
train <- TrainingData[ind==1,]
test <- TrainingData[ind==2,]


library(caret)
tunegrid <-
  expand.grid(
    mtry = c(1:9)
      )
rf <- train(meanwtcpue~. ,
                  data = train ,
            method = "rf",
                   proximity=FALSE, 
                  ntree=500,
                   tuneGrid = tunegrid,
            trControl = trainControl("cv",
            number = 5)
                   )

#Creates a plot of squared error versus number of trees. 
png(paste("Figures/ErrorVsTrees.png"), width = 600, height = 400)
plot(rf$finalModel, main = "Error vs. Trees for Random Forest Model")
dev.off()

print(rf)
print(rf$finalModel)

#linear regression of predicted versus observed values
lmod <- lm(predict(rf, test)~ test$meanwtcpue)
summary(lmod)

#extract the coefficient of observed values from the linear model
coeficient <- as.numeric(lmod$coefficients[2])
coeficient <- round(coeficient, digits = 3)

#plot predicted versus actual values for the whole training data set. 
#add the coeficient of observed values below the chart


#save plot
png(paste("Figures/PredVObserved.png"), width = 800, height = 400)

PredVObserved <- plot(exp(predict(rf, test)), exp(test$meanwtcpue), 
     main = "Predicted versus Observed CPUE (2000-2020)", 
     xlab = "Predicted", 
     ylab = "Observed ", 
     sub = paste("Slope of coeficient:", as.character(coeficient),  "(p < 0.05)"),
     col = "darkcyan",
     pch = 19)
abline(lmod)
dev.off()

#Log Transformed

#saving plot for paper
png(paste("Figures/LogTransformedPredVObserved.png"), width = 600, height = 400)

LogTransformedPredVObserved <- plot((predict(rf, test)), (test$meanwtcpue), 
     main = "Log Predicted versus Log Observed CPUE (2000-2020)", 
     xlab = "Predicted (log transformed)", 
     ylab = "Observed (log transformed)", 
     sub = paste("Slope of coeficient:", as.character(coeficient),  "(p < 0.05)"),
     pch = 19)
abline(lmod)
dev.off()

#feature importance
png("Figures/FeatureImportance.png", width = 600, height = 400)
randomForest::varImpPlot(
  rf$finalModel,
  main = "Feature Importance"
)
dev.off
```

### Creating 2010 baseline with model

```{r 2010 Prediction}

year <- 2010
latitude_pred <- c(52, 64)
longitude_pred <- c(-179.75, 179.75)
LayerNames2010_pred <- c()
#uses lat bounded by bering sea, and lon for a global swath
#allows rewrapping around antimeridian
for (i in 1:length(LayerList)) {
 layer = biooracle_download(LayerList[[i]], 
                     VarList[[i]], 
                     year, 
                     latitude_pred, 
                     longitude_pred)
  assign(paste0(names(LayerList[i]),as.character(year),
                "_pred"), layer )
  remove(layer) #gets rid of last duplicate layer
  LayerNames2010_pred <-
    append(LayerNames2010_pred, 
           paste0(names(LayerList[i]),as.character(year),"_pred"))
  }
#depth
Depth_pred <- biooracle_download("terrain_characteristics",
                   depthvariables, 
                   1970, 
                   latitude_pred, 
                   longitude_pred)
####################

#Create a new data frame for all the properties used in the model
LayerNames2010_pred <- append(LayerNames2010_pred, "Depth_pred")
RegionData2010 <- lapply(lapply(LayerNames2010_pred, FUN = get),
                         FUN = terra::values)%>%data.frame()%>%
  mutate(depth = bathymetry_mean)%>%mutate(bathymetry_mean = NULL)




#Creates copy of Bio-ORACLE raster then overwrites data with model predictions
#Assigns a new object to one of the Bio-ORACLE layers. Ensures that all spatial information is maintained. 
Pollock2010_pred <- o22010_pred

#un-log transform data
values(Pollock2010_pred)[!is.na(values(Pollock2010_pred))] <- 
  exp(predict(rf$finalModel, newdata = na.omit(RegionData2010)))

Pollock2010_pred <- terra::rotate(Pollock2010_pred)
e <- ext(-200, -150, 52, 64)
Pollock2010_pred <-crop(Pollock2010_pred , e)
#Plot the whole prediction map


  colorscheme <- scale_fill_gradient2(
    low = "black",     # Low values
    mid = "blue4",    # Midpoint
    high = "yellow",     # High values
    midpoint = 40,     # Center value
    name = "Pollock CPUE (kg/ha)",
    limits = c(0,300))
  
#save interpolated map   
png("Figures/PollockMap(2010).png")
ggplot() + geom_spatraster(data = Pollock2010_pred) + 
  labs(title = "2010 Predicted Pollock Weight Catch per Unit effort (kg/ha)")+ 
  colorscheme+
theme_bw()
dev.off()
```

## Model Prediction

Using the random forest model and 2040 conditions predicted under SSP3-7.0 (A likely climate pathway with some degree of emissions reduction), the above process is repeated. The study range is expanded to include the whole Bering sea. Due to International Date Line dividing the study area and the way that Bio-ORACLE downloads layers, an entire strip of the world is downloaded from 45 to 75 degrees latitude. Bio-ORACLE data has a strip of missing information of 0.5 degrees along the anti-meridian. This makes the movement of the highest quality zones of the fishery hard to visualize.

To better visualize this data for the report, the final raster is exported as a GeoTIFF to be re-projected in ArcGISPro.

```{r SelectClimatePathway}

LayerList_pred <- #text manipulate layer names to be future pathway IDs
  lapply(LayerList, pattern = "baseline",replacement = pathway, FUN = sub) %>%
  lapply(LayerList, pattern = "2000_2018", 
         replacement = "2020_2100", FUN = gsub)%>%
  lapply(LayerList, pattern = "2000_2019", 
         replacement = "2020_2100", FUN = gsub)%>%
  lapply(LayerList, pattern = "2000_2020", 
         replacement = "2020_2100", FUN = gsub)
LayerList_pred

```

### Predicted layer

```{r PollockPrediction}

latitude_pred <- c(52, 64)
longitude_pred <- c(-179.975, 179.975)
LayerNames_pred <- c()
#uses lat bounded by bering sea, and lon for a global swath
#allows rewrapping around antimeridian
for (i in 1:length(LayerList)) {
 layer = biooracle_download(LayerList_pred[[i]], 
                     VarList[[i]], 
                     year_to_predict, 
                     latitude_pred, 
                     longitude_pred)
  assign(paste0(names(LayerList[i]),as.character(year_to_predict),
                "_pred"), layer )
  remove(layer) #gets rid of last duplicate layer
  LayerNames_pred <-
    append(LayerNames_pred, 
           paste0(names(LayerList[i]),as.character(year_to_predict),"_pred"))
  }
#depth
Depth_pred <- biooracle_download("terrain_characteristics",
                   depthvariables, 
                   1970, 
                   latitude_pred, 
                   longitude_pred)
####################

#Create a new data frame for all the properties used in the model
LayerNames_pred <- append(LayerNames_pred, "Depth_pred")
RegionData_pred <- lapply(lapply(LayerNames_pred, FUN = get),
                         FUN = terra::values)%>%data.frame()%>%
  mutate(depth = bathymetry_mean)%>%mutate(bathymetry_mean = NULL)




#Creates copy of Bio-ORACLE raster then overwrites data with model predictions
#Assigns a new object to one of the Bio-ORACLE layers. Ensures that all spatial information is maintained. 
Pollock_pred <- get(paste0(names(LayerList_pred[1]),as.character(year_to_predict),
                          "_pred"))

#un-log transform data
values(Pollock_pred)[!is.na(values(Pollock_pred))] <- 
  exp(predict(rf$finalModel, newdata = na.omit(RegionData_pred)))

Pollock_pred <- terra::rotate(Pollock_pred)
e <- ext(-200, -150, 52, 64)
Pollock_pred <-crop(Pollock_pred , e)
#Plot the whole prediction map


  colorscheme <- scale_fill_gradient2(
    low = "black",     # Low values
    mid = "blue4",    # Midpoint
    high = "yellow",     # High values
    midpoint = 40,     # Center value
    name = "Pollock CPUE (kg/ha)",
    limits = c(0,300))

png(paste0("Figures/PollockMap(",year_to_predict,", ",pathway, ").png"), 
    width = 600, height = 400)    
ggplot() + geom_spatraster(data = Pollock_pred) + 
  labs(title = paste(as.character(year_to_predict), "Predicted Pollock Weight Catch per Unit effort (kg/ha)"))+ 
  colorscheme+
theme_bw()
dev.off()
```

Saving the final prediction layer, outputs to TIF_outputs.

```{r Saving 2040 Layer}
rastername <- file.path(
  paste0("TIF_outputs/Pollock",
         as.character(year_to_predict),
         "(",
         pathway,
         ")",
         "Predicted.tif")) 

writeRaster(Pollock_pred,filename = rastername, overwrite = TRUE) #writes a new raster

```

### Plotting side by side maps of 2010 and future CPUE. Saves as a png in the figures folder.

```{r}
  colorscheme <- scale_fill_gradient2(
    low = "black",     # Low values
    mid = "blue4",    # Midpoint
    high = "yellow",     # High values
    midpoint = 40,     # Center value
    name = "Pollock CPUE (kg/ha)",
    limits = c(0,300))
  
gg2010 <- ggplot() + geom_spatraster(data = Pollock2010_pred)+
  colorscheme + labs(title = "2010 Baseline conditons") + theme_bw()
gg2040 <- ggplot() + geom_spatraster(data = Pollock_pred)+
  colorscheme + labs(title = paste(year_to_predict, "Pathway", pathway)) +theme_bw()
#saving image to folder "Figures"
png(paste0("Figures/PollockMapSidebySide(",year_to_predict,", ",pathway,").png"), 
    width = 600, height = 400)
grid.arrange(gg2010, gg2040, ncol = 1)
dev.off()
```

### Subtracting predicted layer from baseline

Known offset issue here, where predicted layer is not aligned with baseline.

```{r DIffMap}
Change <- Pollock_pred - Pollock2010_pred
MeanChange <- mean(na.omit(values(Change)))%>%
  round(3) #round to reasonable amount of sig figs

  colorscheme <- scale_fill_gradient2(
    low = "red",     # Low values
    mid = "white",    # Midpoint
    high = "blue",     # High values
    midpoint = 0,     # Center value
    name = "Pollock CPUE (kg/ha)",
    limits = c(-260,50))
  
ggChange <- ggplot() + geom_spatraster(data = Change)+
  colorscheme + labs(title = paste("Change in Predicted CPUE",pathway
                                   ,year,"- 2010)"), 
                     caption = "Catch per Unit Effort (CPUE) measured in catch of pollock (kg) per hectare trawled",
                     subtitle = paste("Mean change:",MeanChange, "kg/ha")) +theme_bw()
#saving image
png(paste("Figures/PollockMap",pathway,year_to_predict,"-2010.png"), 
    width = 800, height = 400)
ggChange
dev.off()
```
