latitude = c(45, 75) #latitude bounds of the Bering sea
longitude = c(-179.75, 179.75) #longitude bounds the whole biooracler data set.
constraints = list(time, latitude, longitude) #combines factors defined above
names(constraints) = c("time", "latitude", "longitude") #assign names
#assigns dataset names to ID's for downloading
dataset_idTemp <-"thetao_ssp370_2020_2100_depthmax"
dataset_idSIThick <- "sithick_ssp370_2020_2100_depthsurf"
dataset_idDO <- "o2_ssp370_2020_2100_depthmax"
#Download max benthic temp prediction
MaxTemp2040  <- download_layers(dataset_idTemp,
variables = "thetao_max",
constraints = constraints)
#Download max sea ice thickness prediction
SeaIceThickness2040  <- download_layers(dataset_idSIThick,
variables = "sithick_max",
constraints = constraints)
#download mean dissolved o2 prediction
MeanO22040  <- download_layers(dataset_idDO,
variables = "o2_mean",
constraints = constraints)
#redefines time range to 1970, as that is the time associated with bathymetry layer.
time = c('1970-01-01T00:00:00Z', '1970-01-01T00:00:00Z')
constraints = list(time, latitude, longitude) #combines factors defined above, uses same lat and long with redefined time.
names(constraints) = c("time", "latitude", "longitude")
dataset_id5 <- "terrain_characteristics"
Depth <- download_layers(dataset_id5,
variables = "bathymetry_mean",
constraints = constraints)
#Combines all downloaded 2040 layers into one dataframe
regiondata <- data.frame(values(MaxTemp2040),
values(SeaIceThickness2040),
values(MeanO22040),
values(Depth))
#rename columns, have to be consistent with model to predict. Only one needing renaming is depth
names(regiondata)[names(regiondata) == "bathymetry_mean"] <- "depth"
#Creates copy of biooracler raster then overwrites data with model predictions
#ensures spatial reference, cells, and area are the same
Pollock2040Predicted <- MeanO22040
#un-log transform data
values(Pollock2040Predicted) <- exp(predict(rf, regiondata))
#Plot the whole prediction map
plot(Pollock2040Predicted, main = "2040 Predicted Pollock Weight Catch per Unit effort (kg/ha)",
cex = 0.9)
saveraster <- FALSE
if(saveraster) {rastername <- "Pollock2040Predicted.tif" #Example Name
writeRaster(Pollock2040Predicted,rastername, overwrite = TRUE)} #writes a new raster
plot(x2010Survey, add = T)
plot(x2010Survey)
plot(test$wtcpue, test$depth)
plot(x2010Survey)
plot(x2010Survey$wtcpue,x2010Survey$LON)
#Define 2040 Conditions
time = c('2040-01-01T00:00:00Z','2040-01-01T00:00:00Z') #Sets time to 2040 decade
latitude = c(45, 75) #latitude bounds of the Bering sea
longitude = c(-179.75, 179.75) #longitude bounds the whole biooracler data set.
constraints = list(time, latitude, longitude) #combines factors defined above
names(constraints) = c("time", "latitude", "longitude") #assign names
#assigns dataset names to ID's for downloading
dataset_idTemp <-"thetao_ssp370_2020_2100_depthmax"
dataset_idSIThick <- "sithick_ssp370_2020_2100_depthsurf"
dataset_idDO <- "o2_ssp370_2020_2100_depthmax"
#Download max benthic temp prediction
MaxTemp2040  <- download_layers(dataset_idTemp,
variables = "thetao_max",
constraints = constraints)
#Download max sea ice thickness prediction
SeaIceThickness2040  <- download_layers(dataset_idSIThick,
variables = "sithick_max",
constraints = constraints)
#download mean dissolved o2 prediction
MeanO22040  <- download_layers(dataset_idDO,
variables = "o2_mean",
constraints = constraints)
#redefines time range to 1970, as that is the time associated with bathymetry layer.
time = c('1970-01-01T00:00:00Z', '1970-01-01T00:00:00Z')
constraints = list(time, latitude, longitude) #combines factors defined above, uses same lat and long with redefined time.
names(constraints) = c("time", "latitude", "longitude")
dataset_id5 <- "terrain_characteristics"
Depth <- download_layers(dataset_id5,
variables = "bathymetry_mean",
constraints = constraints)
#Combines all downloaded 2040 layers into one dataframe
regiondata <- data.frame(values(MaxTemp2040),
values(SeaIceThickness2040),
values(MeanO22040),
values(Depth))
#rename columns, have to be consistent with model to predict. Only one needing renaming is depth
names(regiondata)[names(regiondata) == "bathymetry_mean"] <- "depth"
#Creates copy of biooracler raster then overwrites data with model predictions
#ensures spatial reference, cells, and area are the same
Pollock2040Predicted <- MeanO22040
#un-log transform data
values(Pollock2040Predicted) <- exp(predict(rf, regiondata))
#Plot the whole prediction map
plot(Pollock2040Predicted, main = "2040 Predicted Pollock Weight Catch per Unit effort (kg/ha)",
cex = 0.9)
plot(MaxTemp2040)
remove(Pollock2040Predicted)
remove(SeaIceThickness2040)
plot(x2010Survey)
1+1
remove(rf)
#reads the trawl survey CSV into R as an object survey.points.data.
survey.points.data <- read.csv("survey-points-data.csv")
#reads subset of survey.points by year
x2010Survey <- subset(survey.points.data, (Year == 2010))
x2010Survey <- subset(x2010Survey, (wtcpue < 400 & wtcpue > 1 ))
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
time = c('2010-01-01T00:00:00Z', '2010-01-01T00:00:00Z') #2010 layer date
latitude = c(52, 64) #latitude bounds of the 2010 Trawl data
longitude = c(-157, -179.975) #longitude bounds of the 2010 Trawl data
constraints2010 = list(time, latitude, longitude) #combines factors defined above
names(constraints2010) = c("time", "latitude", "longitude") #assigns names to each constraint so biooracler can read them
#sea ice thickness baseline layer name
dataset_id <- "sithick_baseline_2000_2020_depthsurf"
#takes in layer name, variables desired and constraints and assings to a new SpatRaster
SeaIceThickness2010  <- download_layers(dataset_id,
variables = "sithick_max",
constraints = constraints2010)
#Plots newly loaded raster
plot(SeaIceThickness2010, main = "Maximum Sea Ice Thickness (m)")
#dissolved molecular oxygen baseline layer name
dataset_id3 <- "o2_baseline_2000_2018_depthmax"
#takes in layer name, variables desired and constraints and assigns to a new SpatRaster
DOMean2010  <- download_layers(dataset_id3,
variables = "o2_mean",
constraints = constraints2010)
#Plots newly loaded raster
plot(DOMean2010, main = "Mean Dissolved Bolecular Oxygen at Depth (mmol / m^3)")
#Maximum benthic sea temperature baseline layer name
dataset_id <- "thetao_baseline_2000_2019_depthmax"
#takes in layer name, variables desired and constraints and assigns to a new SpatRaster
TempMax2010  <- download_layers(dataset_id,
variables = "thetao_max",
constraints = constraints2010)
#Plots newly loaded raster
plot(TempMax2010, main = "Max Benthic Temp (C)")
#redefine constrains to fit within 1970 time frame of bathymetry
time = c('1970-01-01T00:00:00Z', '1970-01-01T00:00:00Z')
latitude = c(52, 64) #Latitude bounds of 2010 Trawl data
longitude = c(-157, -179.975) #Longitude bounds of the 2010 Trawl data
constraints1970 = list(time, latitude, longitude) #combines factors defined above
names(constraints1970) = c("time", "latitude", "longitude") #Have to assign names to constraints for bioracler
#takes in layer name, variables desired and constraints and assigns to a new Spat Raster
dataset_id5 <- "terrain_characteristics"
Depth <- download_layers(dataset_id5,
variables = "bathymetry_mean", #mean of bathymetry in each cell.
constraints = constraints1970)
#Plots newly loaded raster
plot(Depth, main = "Depth (M)")
#Creates a new matrix of the lattitudes and longitudes of every trawl
b <- cbind(x2010Survey$LON, x2010Survey$LAT)
#The "extract" function takes in a lat and long and outputs the value of the raster at that point
#by using it on the whole matrix b, it outputs a list in order of the raster values.
#process is repeated for all bio-ORACLE layers before being bound into a single data frame
MultipleData <- data.frame(extract(SeaIceThickness2010,b),
extract(TempMax2010,b),
extract(DOMean2010,b),
extract(Depth,b),
x2010Survey$LON,
x2010Survey$LAT,
x2010Survey$wtcpue)
#Creates new data frame with the latitudes and longitudes removed.
TrainingData <- data.frame(MultipleData$thetao_max,
MultipleData$sithick_max,
MultipleData$o2_mean,
MultipleData$bathymetry_mean,
MultipleData$x2010Survey.wtcpue)
#Rename columns. Otherwise all column names are preceded with MultipleData. Nicer to read.
names(TrainingData)[names(TrainingData) == "MultipleData.thetao_max"] <- "thetao_max"
names(TrainingData)[names(TrainingData) == "MultipleData.sithick_max"] <- "sithick_max"
names(TrainingData)[names(TrainingData) == "MultipleData.o2_mean"] <- "o2_mean"
names(TrainingData)[names(TrainingData) == "MultipleData.bathymetry_mean"] <- "depth"
names(TrainingData)[names(TrainingData) == "MultipleData.x2010Survey.wtcpue"] <- "wtcpue"
#Displays the first few rows of the data.
head(TrainingData)
plot(TrainingData)
plot(TrainingData)
plot(TrainingData)
1+1
gc()
plot(TrainingData)
plot(c(1),c(1))
plot(TrainingData)
plot(1)
print("rea")
plot(TrainingData)
plot(TrainingData)
plot(1)
knitr::opts_chunk$set(echo = TRUE)
#reads the trawl survey CSV into R as an object survey.points.data.
survey.points.data <- read.csv("survey-points-data.csv")
setwd("~/")
#reads the trawl survey CSV into R as an object survey.points.data.
survey.points.data <- read.csv("survey-points-data.csv")
#reads the trawl survey CSV into R as an object survey.points.data.
survey.points.data <- read.csv("survey-points-data.csv")
survey.points.data <- read.csv("survey-points-data.csv")
#reads subset of survey.points by year
x2010Survey <- subset(survey.points.data, (Year >= 2010 & Year <= 2020))
x2010Survey <- subset(x2010Survey, (wtcpue < 400 & wtcpue > 1 ))
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
#reads the trawl survey CSV into R as an object survey.points.data.
survey.points.data <- read.csv("survey-points-data.csv")
View(x2010Survey)
x2010Survey <- subset(x2010Survey, (wtcpue < 400 & wtcpue > 1 ))
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
x2010Survey <- subset(x2010Survey, (wtcpue < 400 & wtcpue > 1 ))
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
x2010Survey <- subset(x2010Survey, (wtcpue < 400 & wtcpue > 1 ))
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
#reads the trawl survey CSV into R as an object survey.points.data.
#survey.points.data <- read.csv("survey-points-data.csv")
#reads subset of survey.points by year
x2010Survey <- subset(survey.points.data, (Year >= 2010 & Year <= 2020))
x2010Survey <- subset(x2010Survey, (wtcpue < 400 & wtcpue > 1 ))
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
time = c('2010-01-01T00:00:00Z', '2010-01-01T00:00:00Z') #2010 layer date
latitude = c(52, 64) #latitude bounds of the 2010 Trawl data
longitude = c(-157, -179.975) #longitude bounds of the 2010 Trawl data
constraints2010 = list(time, latitude, longitude) #combines factors defined above
names(constraints2010) = c("time", "latitude", "longitude") #assigns names to each constraint so biooracler can read them
#sea ice thickness baseline layer name
dataset_id <- "sithick_baseline_2000_2020_depthsurf"
#takes in layer name, variables desired and constraints and assings to a new SpatRaster
SeaIceThickness2010  <- download_layers(dataset_id,
variables = "sithick_max",
constraints = constraints2010)
#Libraries for general use.
library(biooracler)
library(terra)
#Used for Random Forest Model.
library(randomForest)
library(caret)
View(x2010Survey)
1+1
1=1
1 == 1
install.packages("terra")
install.packages("randomForest")
knitr::opts_chunk$set(echo = TRUE)
#Libraries for general use.
library(biooracler)
library(terra)
#Used for Random Forest Model.
library(randomForest)
library(caret)
#reads the trawl survey CSV into R as an object survey.points.data.
#survey.points.data <- read.csv("survey-points-data.csv")
#reads subset of survey.points by year
x2010Survey <- subset(survey.points.data, (Year >= 2010 & Year <= 2020))
x2010Survey <- subset(x2010Survey, (wtcpue < 400 & wtcpue > 1 ))
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
time = c('2010-01-01T00:00:00Z', '2010-01-01T00:00:00Z') #2010 layer date
latitude = c(52, 64) #latitude bounds of the 2010 Trawl data
longitude = c(-157, -179.975) #longitude bounds of the 2010 Trawl data
constraints2010 = list(time, latitude, longitude) #combines factors defined above
names(constraints2010) = c("time", "latitude", "longitude") #assigns names to each constraint so biooracler can read them
#sea ice thickness baseline layer name
dataset_id <- "sithick_baseline_2000_2020_depthsurf"
#takes in layer name, variables desired and constraints and assings to a new SpatRaster
SeaIceThickness2010  <- download_layers(dataset_id,
variables = "sithick_max",
constraints = constraints2010)
#Plots newly loaded raster
plot(SeaIceThickness2010, main = "Maximum Sea Ice Thickness (m)")
knitr::opts_chunk$set(echo = TRUE)
#Libraries for general use.
library(biooracler)
library(terra)
#Used for Random Forest Model.
library(randomForest)
library(caret)
#reads the trawl survey CSV into R as an object survey.points.data.
#survey.points.data <- read.csv("survey-points-data.csv")
#reads subset of survey.points by year
x2010Survey <- subset(survey.points.data, (Year >= 2010 & Year <= 2020))
x2010Survey <- subset(x2010Survey, (wtcpue < 400 & wtcpue > 1 ))
x2010Survey$wtcpue <- log(x2010Survey$wtcpue)
time = c('2010-01-01T00:00:00Z', '2010-01-01T00:00:00Z') #2010 layer date
latitude = c(52, 64) #latitude bounds of the 2010 Trawl data
longitude = c(-157, -179.975) #longitude bounds of the 2010 Trawl data
constraints2010 = list(time, latitude, longitude) #combines factors defined above
names(constraints2010) = c("time", "latitude", "longitude") #assigns names to each constraint so biooracler can read them
#sea ice thickness baseline layer name
dataset_id <- "sithick_baseline_2000_2020_depthsurf"
#takes in layer name, variables desired and constraints and assings to a new SpatRaster
SeaIceThickness2010  <- download_layers(dataset_id,
variables = "sithick_max",
constraints = constraints2010)
#Plots newly loaded raster
plot(SeaIceThickness2010, main = "Maximum Sea Ice Thickness (m)")
#dissolved molecular oxygen baseline layer name
dataset_id3 <- "o2_baseline_2000_2018_depthmax"
#takes in layer name, variables desired and constraints and assigns to a new SpatRaster
DOMean2010  <- download_layers(dataset_id3,
variables = "o2_mean",
constraints = constraints2010)
#Plots newly loaded raster
plot(DOMean2010, main = "Mean Dissolved Bolecular Oxygen at Depth (mmol / m^3)")
#Maximum benthic sea temperature baseline layer name
dataset_id <- "thetao_baseline_2000_2019_depthmax"
#takes in layer name, variables desired and constraints and assigns to a new SpatRaster
TempMax2010  <- download_layers(dataset_id,
variables = "thetao_max",
constraints = constraints2010)
#Plots newly loaded raster
plot(TempMax2010, main = "Max Benthic Temp (C)")
#redefine constrains to fit within 1970 time frame of bathymetry
time = c('1970-01-01T00:00:00Z', '1970-01-01T00:00:00Z')
latitude = c(52, 64) #Latitude bounds of 2010 Trawl data
longitude = c(-157, -179.975) #Longitude bounds of the 2010 Trawl data
constraints1970 = list(time, latitude, longitude) #combines factors defined above
names(constraints1970) = c("time", "latitude", "longitude") #Have to assign names to constraints for bioracler
#takes in layer name, variables desired and constraints and assigns to a new Spat Raster
dataset_id5 <- "terrain_characteristics"
Depth <- download_layers(dataset_id5,
variables = "bathymetry_mean", #mean of bathymetry in each cell.
constraints = constraints1970)
#Plots newly loaded raster
plot(Depth, main = "Depth (M)")
#Creates a new matrix of the lattitudes and longitudes of every trawl
b <- cbind(x2010Survey$LON, x2010Survey$LAT)
#The "extract" function takes in a lat and long and outputs the value of the raster at that point
#by using it on the whole matrix b, it outputs a list in order of the raster values.
#process is repeated for all bio-ORACLE layers before being bound into a single data frame
MultipleData <- data.frame(extract(SeaIceThickness2010,b),
extract(TempMax2010,b),
extract(DOMean2010,b),
extract(Depth,b),
x2010Survey$LON,
x2010Survey$LAT,
x2010Survey$wtcpue)
#Creates new data frame with the latitudes and longitudes removed.
TrainingData <- data.frame(MultipleData$thetao_max,
MultipleData$sithick_max,
MultipleData$o2_mean,
MultipleData$bathymetry_mean,
MultipleData$x2010Survey.wtcpue)
#Rename columns. Otherwise all column names are preceded with MultipleData. Nicer to read.
names(TrainingData)[names(TrainingData) == "MultipleData.thetao_max"] <- "thetao_max"
names(TrainingData)[names(TrainingData) == "MultipleData.sithick_max"] <- "sithick_max"
names(TrainingData)[names(TrainingData) == "MultipleData.o2_mean"] <- "o2_mean"
names(TrainingData)[names(TrainingData) == "MultipleData.bathymetry_mean"] <- "depth"
names(TrainingData)[names(TrainingData) == "MultipleData.x2010Survey.wtcpue"] <- "wtcpue"
#Displays the first few rows of the data.
head(TrainingData)
set.seed(222)
#Creates a random list of 70% 1 and 30% 2 that is the same length as the training data.
#Model is trained off all values corresponding to a 1 (70%)
#30% is set aside (assinged a 2)
ind <- sample(2,nrow(TrainingData), replace = TRUE,prob = c(0.7,0.3))
train <- TrainingData[ind==1,]
test <- TrainingData[ind==2,]
rf <- randomForest(wtcpue~., data=train, proximity=FALSE, ntree=500)
#Creates a plot of squared error versus number of trees.
plot(rf, main = "Error vs. Trees for Random Forest Model")
print(rf)
#linear regression of predicted versus observed values
lmod <- lm(predict(rf, TrainingData)~TrainingData$wtcpue)
summary(lmod)
#extract the coefficient of observed values from the linear model
coeficient <- as.numeric(lmod$coefficients[2])
coeficient <- round(coeficient, digits = 3)
#plot predicted versus actual values for the whole training data set.
#add the coeficient of observed values below the chart
plot(predict(rf, TrainingData), TrainingData$wtcpue,
main = "Predicted versus Observed CPUE (2010)",
xlab = "Predicted",
ylab = "Observed",
sub = paste("Slope of coeficient:", as.character(coeficient),  "(p < 0.05)"),
pch = 19)
abline(lmod)
#predict wtcpue for the whole region for 2010
#Create a new data frame for all the properties used in the model
regiondata <- data.frame(values(TempMax2010),
values(SeaIceThickness2010),
values(DOMean2010),
values(Depth))
#rename columns, have to be consistent with model to predict
#have to use the same names as used when training the model
names(regiondata)[names(regiondata) == "thetao_max_2"] <- "thetao_max"
names(regiondata)[names(regiondata) == "sithick_max_2"] <- "sithick_max"
names(regiondata)[names(regiondata) == "o2_mean_2"] <- "o2_mean"
names(regiondata)[names(regiondata) == "bathymetry_mean"] <- "depth"
#Creates copy of Bio-ORACLE raster then overwrites data with model predictions
#Assigns a new object to one of the Bio-ORACLE layers. Ensures that all spatial information is maintained.
Pollock2010Predicted <- DOMean2010
#unlog transform data and overwrite data with predictions of whole region (exp(x)= e^x)
values(Pollock2010Predicted) <- exp(predict(rf, regiondata))
#plot the prediction, add title and reduce text size to 90% of default
plot(Pollock2010Predicted,
main = "2010 Predicted Pollock Weight Catch per Unit effort (kg/ha)",
cex = 0.9)
#Define 2040 Conditions
time = c('2040-01-01T00:00:00Z','2040-01-01T00:00:00Z') #Sets time to 2040 decade
latitude = c(45, 75) #latitude bounds of the Bering sea
longitude = c(-179.75, 179.75) #longitude bounds the whole biooracler data set.
constraints = list(time, latitude, longitude) #combines factors defined above
names(constraints) = c("time", "latitude", "longitude") #assign names
#assigns dataset names to ID's for downloading
dataset_idTemp <-"thetao_ssp370_2020_2100_depthmax"
dataset_idSIThick <- "sithick_ssp370_2020_2100_depthsurf"
dataset_idDO <- "o2_ssp370_2020_2100_depthmax"
#Download max benthic temp prediction
MaxTemp2040  <- download_layers(dataset_idTemp,
variables = "thetao_max",
constraints = constraints)
#Download max sea ice thickness prediction
SeaIceThickness2040  <- download_layers(dataset_idSIThick,
variables = "sithick_max",
constraints = constraints)
#download mean dissolved o2 prediction
MeanO22040  <- download_layers(dataset_idDO,
variables = "o2_mean",
constraints = constraints)
#redefines time range to 1970, as that is the time associated with bathymetry layer.
time = c('1970-01-01T00:00:00Z', '1970-01-01T00:00:00Z')
constraints = list(time, latitude, longitude) #combines factors defined above, uses same lat and long with redefined time.
names(constraints) = c("time", "latitude", "longitude")
dataset_id5 <- "terrain_characteristics"
Depth <- download_layers(dataset_id5,
variables = "bathymetry_mean",
constraints = constraints)
#Combines all downloaded 2040 layers into one dataframe
regiondata <- data.frame(values(MaxTemp2040),
values(SeaIceThickness2040),
values(MeanO22040),
values(Depth))
#rename columns, have to be consistent with model to predict. Only one needing renaming is depth
names(regiondata)[names(regiondata) == "bathymetry_mean"] <- "depth"
#Creates copy of biooracler raster then overwrites data with model predictions
#ensures spatial reference, cells, and area are the same
Pollock2040Predicted <- MeanO22040
#un-log transform data
values(Pollock2040Predicted) <- exp(predict(rf, regiondata))
#Plot the whole prediction map
plot(Pollock2040Predicted, main = "2040 Predicted Pollock Weight Catch per Unit effort (kg/ha)",
cex = 0.9)
rf
View(rf)
a <p c(rf)
a < c(rf)
a <- c(rf)
TT.points.in.classes(SoilColumnTestingSpring25Long[5:3], class.sys = "USDA.TT", css.names = c("Clay","Silt","Sand"))
col.pal <- c("darkblue", "sienna", "darkgreen")
TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
TT.points.in.classes(SoilColumnTestingSpring25Long[5:3], class.sys = "USDA.TT", css.names = c("Clay","Silt","Sand"))
SoilCOlumnTestingSpring25Long <- read.csv("C:\Users\zesty\Downloads\SoilColumnChart.R")
SoilCOlumnTestingSpring25Long <- read.csv("C:/Users/zesty/Downloads/SoilColumnTestingSpring25Long.csv")
remove(SoilCOlumnTestingSpring25Long)
SoilColumnTestingSpring25Long <- read.csv("C:/Users/zesty/Downloads/SoilColumnTestingSpring25Long.csv")
TT.points.in.classes(SoilColumnTestingSpring25Long[5:3], class.sys = "USDA.TT", css.names = c("Clay","Silt","Sand"))
col.pal <- c("darkblue", "sienna", "darkgreen")
TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
library(soiltexture)
SoilColumnTestingSpring25Long <- read.csv("C:/Users/zesty/Downloads/SoilColumnTestingSpring25Long.csv")
TT.points.in.classes(SoilColumnTestingSpring25Long[5:3], class.sys = "USDA.TT", css.names = c("Clay","Silt","Sand"))
col.pal <- c("darkblue", "sienna", "darkgreen")
TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
TT.baseplot(class.sys="USDA.TT")
TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
gc()
SoilColumnTestingSpring25Long <- read.csv("C:/Users/zesty/Downloads/SoilColumnTestingSpring25Long.csv")
TT.points.in.classes(SoilColumnTestingSpring25Long[5:3], class.sys = "USDA.TT", css.names = c("Clay","Silt","Sand"))
col.pal <- c("darkblue", "sienna", "darkgreen")
TT.baseplot(class.sys="USDA.TT")
TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
Plot <- TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
Plot
TT.baseplot(class.sys="USDA.TT")
Plot <- TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
SoilColumnTestingSpring25Long <- read.csv("C:/Users/zesty/Downloads/SoilColumnTestingSpring25Long.csv")
TT.points.in.classes(SoilColumnTestingSpring25Long[5:3], class.sys = "USDA.TT", css.names = c("Clay","Silt","Sand"))
col.pal <- c("darkblue", "sienna", "darkgreen")
TT.baseplot(class.sys="USDA.TT")
Plot <- TT.points(SoilColumnTestingSpring25Long[5:3],
geo = TT.plot(class.sys = "USDA.TT"),
css.names = c("Clay","Silt","Sand"),
col = col.pal[factor(SoilColumnTestingSpring25Long$Soil.Series)])
plot(Plot)
plot(SoilColumnTestingSpring25Long$Soil.Series, SoilColumnTestingSpring25Long$Silt)
plot(SoilColumnTestingSpring25Long$Sand, SoilColumnTestingSpring25Long$Silt)
